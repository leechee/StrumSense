# StrumSense - Project Summary

## What I Built

A fully functional AI-powered acoustic guitar cover recommendation web app that:

1. **Analyzes your playing** - Upload an acoustic guitar recording and get detailed analysis
2. **Recognizes songs** - Uses AI to identify what you're playing
3. **Recommends covers** - Suggests 10 personalized songs based on your style and mood
4. **Learns your taste** - Builds a profile over time to improve recommendations

## Key Features Implemented

### 1. Audio Analysis Engine
- **Python/librosa** for professional audio analysis
- Extracts: tempo (BPM), key signature, chords, playing style
- Detects: brightness, energy level, fingerstyle vs strumming
- Generates vibe tags: mellow, upbeat, dark, bright, etc.

### 2. AI Song Recognition
- **OpenAI GPT-4** integration for song identification
- Provides confidence scores for matches
- Generates natural language descriptions of playing style
- Works even when song can't be identified

### 3. Smart Recommendation Engine
- **Multi-factor scoring algorithm**:
  - Tempo similarity (Â±10 BPM = best match)
  - Key and chord overlap
  - Vibe/mood matching
  - Difficulty level alignment
  - User preference history
- **30+ curated songs** with complete metadata:
  - Chords, tempo, key, capo position
  - Difficulty ratings
  - Playing techniques
  - Genre and mood tags

### 4. User Profile System
- Tracks all uploads automatically
- Learns preferred keys, tempos, genres
- Improves recommendations over time
- Stored locally in JSON format

### 5. Beautiful UI
- Modern gradient design (purple theme)
- Drag-and-drop audio upload
- Mood selector with 7 options
- Real-time analysis progress
- Detailed song cards with match reasons
- Mobile-responsive layout

## Tech Stack

### Frontend
- **Next.js 14** - React framework with API routes
- **React** - UI components
- **CSS Modules** - Scoped styling

### Backend
- **Node.js** - Server runtime
- **Vercel** - Deployment platform
- **Formidable** - File upload handling

### Audio Analysis
- **Python 3.11** (conda environment)
- **librosa** - Audio feature extraction
- **numpy/scipy** - Numerical computing

### AI Integration
- **OpenAI GPT-4** - Song recognition
- **OpenAI GPT-3.5** - Vibe descriptions

## Project Structure

```
StrumSense/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ index.js                      # Main UI (React)
â”‚   â”œâ”€â”€ _app.js                       # Next.js wrapper
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ analyze-audio.js          # Audio upload & analysis
â”‚       â”œâ”€â”€ save-upload.js            # User history tracking
â”‚       â”œâ”€â”€ demo.js                   # Demo mode (no upload)
â”‚       â””â”€â”€ health.js                 # Health check endpoint
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ acousticSongsDatabase.js      # 30+ songs with metadata
â”‚   â”œâ”€â”€ audioAnalyzer.js              # Node.js wrapper for Python
â”‚   â”œâ”€â”€ songRecognition.js            # OpenAI integration
â”‚   â”œâ”€â”€ recommendationEngine.js       # Scoring algorithm
â”‚   â””â”€â”€ testData.js                   # Sample data for testing
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ audio_analyzer.py             # Python audio analysis
â”‚
â”œâ”€â”€ styles/
â”‚   â”œâ”€â”€ globals.css                   # Global styles
â”‚   â””â”€â”€ Home.module.css               # Component styles
â”‚
â”œâ”€â”€ data/                              # Auto-generated
â”‚   â””â”€â”€ user-history.json             # User profiles
â”‚
â”œâ”€â”€ uploads/                           # Auto-generated
â”‚   â””â”€â”€ (temporary audio files)
â”‚
â”œâ”€â”€ package.json                       # Node dependencies
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ vercel.json                        # Vercel config
â”œâ”€â”€ next.config.js                     # Next.js config
â”œâ”€â”€ .env.local                         # Environment variables
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ README.md                          # Full documentation
â”œâ”€â”€ QUICKSTART.md                      # Quick setup guide
â”œâ”€â”€ PROJECT_SUMMARY.md                 # This file
â””â”€â”€ setup-conda.bat                    # Automated setup script
```

## How It Works (End-to-End)

1. **User uploads audio** â†’ Frontend sends to `/api/analyze-audio`
2. **Audio saved temporarily** â†’ Formidable handles file upload
3. **Python analysis** â†’ Node spawns conda Python process
4. **Feature extraction** â†’ librosa analyzes tempo, key, chords, vibe
5. **AI recognition** â†’ OpenAI attempts to identify the song
6. **Recommendation scoring** â†’ Algorithm scores all 30+ songs
7. **Top 10 returned** â†’ Sorted by match score with reasons
8. **Profile updated** â†’ User history saved to JSON
9. **Results displayed** â†’ Beautiful UI shows analysis & recommendations

## Recommendation Algorithm Details

### Scoring Components (Max 100 points)

1. **Tempo Similarity** (25 pts max)
   - Within Â±10 BPM: 25 points
   - Within Â±20 BPM: 15 points
   - Within Â±30 BPM: 10 points

2. **Key Similarity** (20 pts max)
   - Exact key match: 20 points
   - Related keys: 10 points

3. **Chord Overlap** (30 pts max)
   - Based on chord matching ratio

4. **Vibe Matching** (5 pts per match)
   - Matches on: mellow, bright, upbeat, etc.

5. **Mood Alignment** (30 pts max)
   - Direct mood match: 30 points
   - Related mood: 20 points

6. **User Preferences** (up to 28 pts)
   - Genre preference: 10 pts
   - Mood preference: 5 pts each
   - Tempo preference: 10 pts
   - Key preference: 8 pts

7. **Difficulty Match** (15 pts max)
   - Same level: 15 points
   - One level off: 8 points

## Song Database Highlights

30+ songs including:
- **Classics**: Wonderwall, Blackbird, Hotel California
- **Modern**: Thinking Out Loud, Riptide, Let Her Go
- **Folk**: Fast Car, The Boxer, Landslide
- **Indie**: Ho Hey, Skinny Love, Budapest
- **Blues/Soul**: Tears in Heaven, Ain't No Sunshine

Each with:
- Complete chord progressions
- Tempo and key information
- Capo position
- Difficulty rating (beginner/intermediate/advanced)
- Playing techniques
- Vibe and mood tags

## Setup & Usage

### Quick Start
```bash
# 1. Install Node dependencies
npm install

# 2. Create conda environment
conda create -n strumsense python=3.11 -y

# 3. Install Python libraries
conda run -n strumsense pip install librosa numpy scipy

# 4. Add OpenAI API key to .env.local

# 5. Start dev server
npm run dev
```

### Using the App
1. Open http://localhost:3000
2. Upload 30-60 sec acoustic guitar audio
3. Select a mood (optional)
4. Click "Get Recommendations"
5. View your analysis and song suggestions

### Demo Mode
Test without uploading:
- Visit `/api/demo?style=slow_fingerstyle&mood=chill`
- Styles: slow_fingerstyle, upbeat_strumming, melancholic_minor

## Environment Setup

The app uses a **conda environment** for Python:
- Name: `strumsense`
- Python version: 3.11
- Required libraries: librosa, numpy, scipy

The Node.js backend automatically uses this environment via:
```javascript
conda run -n strumsense python scripts/audio_analyzer.py [file]
```

## API Endpoints

### POST `/api/analyze-audio`
- Upload audio file + optional mood
- Returns: analysis + recommendations

### POST `/api/save-upload`
- Save upload to user history
- Updates user preference profile

### GET `/api/demo`
- Test recommendations without upload
- Query params: `style`, `mood`

### GET `/api/health`
- Check server and API key status

## Current Status

 **Fully Functional**
- All core features implemented
- Audio analysis working
- AI recognition integrated
- Recommendation engine optimized
- User profiles tracking
- Beautiful responsive UI

## Future Enhancements

Potential additions:
- Real-time browser audio recording
- YouTube tutorial links
- Spotify playlist export
- Chord progression visualizations
- Social sharing features
- Mobile app (React Native)
- Advanced fingerstyle detection
- Practice difficulty tracking

## Dependencies Summary

### Node.js (package.json)
- next, react, react-dom
- openai (AI integration)
- formidable (file uploads)
- @vercel/blob (Vercel storage)
- music-metadata (audio metadata)

### Python (conda env)
- librosa (audio analysis)
- numpy (numerical computing)
- scipy (signal processing)

## Deployment

Ready for Vercel deployment:
```bash
vercel
```

Environment variables needed:
- `OPENAI_API_KEY` - OpenAI API key
- `BLOB_READ_WRITE_TOKEN` - Vercel blob storage (optional)

## Performance

- Audio analysis: ~5-15 seconds
- Song recognition: ~3-5 seconds
- Recommendation scoring: <1 second
- Total time: ~10-20 seconds per upload

## File Limits

- Max upload size: 10MB
- Supported formats: MP3, WAV, M4A
- Recommended length: 30-60 seconds
- Sample rate: Auto-converted to 22050 Hz

---

**Built with AI to help guitarists discover their next acoustic cover!** ¸
